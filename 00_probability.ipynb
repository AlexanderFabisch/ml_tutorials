{
 "metadata": {
  "celltoolbar": "Slideshow",
  "name": "",
  "signature": "sha256:080af570d86e735bff048215ad229ce61d620ef60818c267d0eb9616b94671a9"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Probability Theory for Machine Learning"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "<center>\n",
      "**There is (almost) no machine learning algorithm that cannot be interpreted from a probabilistic perspective.**\n",
      "</center>\n",
      "\n",
      "For some algorithms that will be more obvious than for others, e.g.\n",
      "\n",
      "* Gaussian Mixture Models (Clustering, Regression)\n",
      "* Naive Bayes (Classification)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Probability\n",
      "----------\n",
      "\n",
      "Let $A$ be the outcome of a random experiment. $P(A)$ is its probability and\n",
      "\n",
      "* $0 \\leq P(A) \\leq 1$\n",
      "* $P(A) = 1$ means the random experiment will **always** have the outcome $A$\n",
      "* $P(A) = 0$ means the random experiment will **never** have the outcome $A$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Interpretations\n",
      "--------------\n",
      "\n",
      "**Bayesian**: $P(A) = 0.9$ means we **believe** that the outcome of the random experiment is $A$ with 90 % confidence.\n",
      "\n",
      "**Frequentist**: $P(A) = 0.9$ means if we repeated the random experiment **infinitely** often we would get the outcome $A$ in 90 % of all cases."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Joint Distribution\n",
      "----------------\n",
      "\n",
      "Probability of observing $A$ **and** $B$\n",
      "\n",
      "$$P(A, B) = P(A) P(B)$$\n",
      "\n",
      "Conditional Distribution\n",
      "----------------------\n",
      "\n",
      "Probability of observing $A$ given $B$ has been observed\n",
      "\n",
      "$$P(A|B) = \\frac{P(A \\cap B)}{P(B)}$$\n",
      "\n",
      "Independence\n",
      "-----------\n",
      "\n",
      "Outcomes $A$ and $B$ are **independend** ($A \\perp B$) iff (if and only if)\n",
      "\n",
      "$$P(A|B) = P(A) \\text{ which is the same as } P(A \\cap B) = P(A) P(B)$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Bayes' Theorem\n",
      "-------------\n",
      "\n",
      "$$P(B|A) = \\frac{P(A|B) P(B)}{P(A)}$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Some Vocabularies\n",
      "---------------\n",
      "\n",
      "Let\n",
      "\n",
      "* $\\mathcal{D}$ be a set of observations (e.g. a training set),\n",
      "* $H$ is a **hypothesis**\n",
      "\n",
      "We call\n",
      "\n",
      "* $P(H)$ is a **prior**; it is usually determined be the user\n",
      "* $P(\\mathcal{D})$ the **evidence**; usually all observations are equiprobable\n",
      "* $P(\\mathcal{D} | H)$\n",
      "    * probability of the observations for fixed $H$\n",
      "    * **likelihood** of the hypothesis for fixed $\\mathcal{D}$, also $P(\\mathcal{D} | H) = \\mathcal{L}(H | \\mathcal{D})$\n",
      "* $P(H | \\mathcal{D})$ the posterior"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Bayesian Inference\n",
      "----------------\n",
      "\n",
      "$$P(H|\\mathcal{D}) = \\frac{P(\\mathcal{D}|H) P(H)}{P(\\mathcal{D})}$$\n",
      "\n",
      "$$\\text{posterior} = \\frac{\\text{likelihood} \\times \\text{prior}}{\\text{evidence}}$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "What Does Learning Mean?\n",
      "----------------------\n",
      "\n",
      "Learning means optimizing the hypothesis with respect to a given objective, e.g.\n",
      "\n",
      "Maximum Likelihood Estimate (MLE)\n",
      "------------------------------\n",
      "\n",
      "$H_{\\text{MLE}} = \\arg \\max_H \\mathcal{L}(H | \\mathcal{D})$\n",
      "\n",
      "Maximum a Postiori Estimate (MAP)\n",
      "------------------------------\n",
      "\n",
      "$H_{\\text{MAP}} = \\arg \\max_H \\mathcal{L}(H | \\mathcal{D}) P(H)$\n",
      "\n",
      "Notes\n",
      "-----\n",
      "\n",
      "* the evidence $P(\\mathcal{D})$ does not change the maximum\n",
      "* often the log-likelihood $\\log \\mathcal{L}$ will be optimized\n",
      "* MAP is usually a **regularized** version of the MLE, i.e. it generalizes better over unseen data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "References\n",
      "---------\n",
      "\n",
      "[1] Murphy, Kevin P.: Machine Learning - A Probabilistic Perspective, 2012, MIT Press."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}